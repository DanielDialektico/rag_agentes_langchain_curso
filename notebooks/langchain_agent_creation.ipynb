{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO76agMJmvgcnIOn43JgmiS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_agent_creation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG y agentes con LangChain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librerías.\n",
        "!pip install langchain==0.3.21\n",
        "!pip install langchain-community==0.3.20\n",
        "!pip install langchain_deepseek==0.1.2\n",
        "!pip install langgraph==0.3.31\n",
        "!pip install duckduckgo-search==8.0.0"
      ],
      "metadata": {
        "id": "8U_GtE_0tuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "# Se importan las librerías.\n",
        "import warnings\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "from google.colab import userdata\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "import pandas as pd\n",
        "\n",
        "# Filtro para advertencias.\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Añadiendo y utilizando una herramienta de búsqueda web"
      ],
      "metadata": {
        "id": "4lxITC5Y8I9o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Existen diferentes herramientas predefinidas en LangChain, que pueden ser coconsultadas en la siguiente URL: https://python.langchain.com/docs/integrations/tools/\n",
        "\n",
        "Nosotros utilizaremos el buscador web DuckDuckGo, el cual puede ser consultado en: https://python.langchain.com/docs/integrations/tools/ddg/"
      ],
      "metadata": {
        "id": "i4hH18xxZcYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la herramienta del buscador web.\n",
        "search = DuckDuckGoSearchResults(max_results=5, description=\"\"\"Herramienta que\n",
        "puede ser utilizada para buscar información en internet, se puede buscar el\n",
        "clima del día actual, por ejemplo: ¿cuál es la temperatura en Guadalajara\n",
        "Jalisco el día de hoy?\"\"\")\n",
        "\n",
        "# Se prueba.\n",
        "search.invoke(\"Temperatura de hoy en Guadalajara Jalisco\")"
      ],
      "metadata": {
        "id": "hIuxRdvTB71L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora utilizaremos este buscador como herramienta de una LLM."
      ],
      "metadata": {
        "id": "VbGm3eLwZ1s0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "# Se define el modelo a utilizar y añaden valores de parámetros.\n",
        "model = ChatDeepSeek(\n",
        "      model=\"deepseek-chat\",\n",
        "      temperature=0,\n",
        "      max_tokens=200\n",
        "      )"
      ],
      "metadata": {
        "id": "ksza_EkW9vTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade el buscador web a una lista de herramientas.\n",
        "tools = [search]\n",
        "\n",
        "# Se añade al modelo.\n",
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "erHBgYXcuKSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"¿Cuál es la temperatura en Guadalajara, Jalisco, México?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "id": "W6871_QS-HE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "Q1tXoBZWaOu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creando agente con LangGraph"
      ],
      "metadata": {
        "id": "GlY5WRSfcehr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora utilizaremos `create_react_agent` para crear un agente que utilice esta herramienta. Este flujo funciona como un grafo, donde el nodo \"agent\" llama al modelo de lenguaje con la lista de mensajes añadidos. Si el AIMessage resultante contiene tool_calls, el grafo llamará entonces a los \"tools\". El nodo \"tools\" ejecuta las herramientas (una herramienta por cada tool_call) y añade las respuestas a la lista de mensajes como objetos ToolMessage. Luego, el nodo del agente vuelve a llamar al modelo de lenguaje. Este proceso se repite hasta que la respuesta ya no contenga más tool_calls. Finalmente, el agente devuelve la lista completa de mensajes como un diccionario que contiene la clave \"messages\".\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/04/graph_lc.png\" width=\"200\" /></center>\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/04/graph_lc_2.png\" width=\"800\" /></center>"
      ],
      "metadata": {
        "id": "33lubd0eab2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el agente pasando el modelo y las herramientas como argumentos.\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Se realiza una prueba.\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"Cuál es la temperatura en Guadalajara, Jalisco, México?\")]}\n",
        ")\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "id": "t0YE3vTB-Ti6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se filtra el mensaje de tipo AIMessage (aunque usualmente es el último)\n",
        "ai_messages = [m for m in response[\"messages\"] if isinstance(m, AIMessage)]\n",
        "print(ai_messages[-1].content)"
      ],
      "metadata": {
        "id": "Md37Y9Bj-rm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "1PQOZDJTc9ec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creando un agente multi-herramienta (multi-tool agent)"
      ],
      "metadata": {
        "id": "jrniFBBZdC3U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un agente multi-herramienta añadiremos una nueva herramienta a la lista y recrearemos el agente.\n",
        "\n",
        "Lo haremos para crear un agente que atienda a una tienda electrónica de accesorios para mascotas.\n",
        "\n",
        "El agente debe hacer lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "*   Investigar la temperatura de la ciudad donde vive el cliente.\n",
        "*   Conociendo la temperatura, y el tipo de mascota del cliente (perro o gato), extraer información de los productos que puede ofrecer de un CSV.\n",
        "* Dar la información al cliente.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/04/Diagrama_agente.drawio.png\" width=\"1000\" /></center>\n"
      ],
      "metadata": {
        "id": "dldv6GMAdHiL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se crea la herramienta de búsqueda en CSV"
      ],
      "metadata": {
        "id": "av9j1BzjlDJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def obtener_prendas_para_mascota(ruta_csv: str, animal: str, temperatura_aprox: float) -> list[str]:\n",
        "    \"\"\"\n",
        "    Filtra una tabla CSV de prendas para mascotas y devuelve aquellas adecuadas\n",
        "    según el tipo de animal (perro o gato) y la temperatura actual.\n",
        "\n",
        "    La función clasifica la temperatura en una de tres categorías:\n",
        "        - 'frío': temperatura menor a 15°C\n",
        "        - 'templado': temperatura entre 15°C y 25°C (inclusive)\n",
        "        - 'caluroso': temperatura mayor a 25°C\n",
        "\n",
        "    Luego, filtra las prendas que coincidan con la clasificación de temperatura y el animal especificado.\n",
        "\n",
        "    Args:\n",
        "        ruta_csv (str): Ruta al archivo CSV que contiene la tabla de prendas.\n",
        "        animal (str): Tipo de mascota, por ejemplo, 'gato' o 'perro'.\n",
        "        temperatura_actual (float): Temperatura en grados Celsius.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: Lista de nombres de prendas recomendadas para el animal y clima dados.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo CSV en la ruta especificada.\n",
        "        ValueError: Si el tipo de animal no está presente en la tabla.\n",
        "\n",
        "    Example:\n",
        "        >>> obtener_prendas_para_mascota('prendas_mascotas.csv', 'perro', 10)\n",
        "        ['chamarra acolchada impermeable', 'suéter térmico de felpa']\n",
        "    \"\"\"\n",
        "    # Cargar la tabla\n",
        "    df = pd.read_csv(ruta_csv)\n",
        "\n",
        "    # Clasificar la temperatura\n",
        "    if temperatura_aprox < 15:\n",
        "        clasificacion_temp = 'frío'\n",
        "    elif 15 <= temperatura_aprox <= 25:\n",
        "        clasificacion_temp = 'templado'\n",
        "    else:\n",
        "        clasificacion_temp = 'caluroso'\n",
        "\n",
        "    # Verificar si el animal está en el dataset\n",
        "    if animal.lower() not in df['animal'].str.lower().unique():\n",
        "        raise ValueError(f\"Animal '{animal}' no encontrado en la tabla.\")\n",
        "\n",
        "    # Filtrar según clasificación de temperatura y animal\n",
        "    prendas_filtradas = df[\n",
        "        (df['temperatura'] == clasificacion_temp) &\n",
        "        (df['animal'].str.lower() == animal.lower())\n",
        "    ]\n",
        "\n",
        "    return prendas_filtradas['nombre_prenda'].tolist()"
      ],
      "metadata": {
        "id": "P0ayrALDD1Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prueba la función.\n",
        "obtener_prendas_para_mascota('/content/productos.csv', 'perro', 28)"
      ],
      "metadata": {
        "id": "uH49yjEqzo90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el agente con herramientas nuevas.\n",
        "tools = [search, obtener_prendas_para_mascota]\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Se añaden instrucciones.\n",
        "system_message = \"\"\"Eres un asistente de una tienda en línea que vende productos\n",
        "        para mascotas. El cliente te dirá qué mascota tiene (perro o gato) y en\n",
        "        qué ciudad vivo, y tú debes de seguir los siguientes pasos:\n",
        "        - Debes de utilizar la herramienta search para obtener la temperatura\n",
        "        aproximada de la ciudad donde vive, colocando en el buscador:\n",
        "        cuál es el clima actual en {ciudad del cliente}.\n",
        "        - Utilizando la información del buscador, utilizarás la herramienta\n",
        "        obtener_prendas_para_mascota, añadiendo los argumentos correspondientes,\n",
        "        donde el csv con la información está en /content/productos.csv, y añades\n",
        "        tipo de animal y temperatura aproximada para obtener los datos.\n",
        "        - Utilizando estos datos, dile al cliente qué prendas puedes ofrecer.\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "qLJ0wpnzUXAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza el agente haciendo stream en la respuesta.\n",
        "for step, metadata in agent_executor.stream(\n",
        "    {\"messages\": [SystemMessage(\n",
        "        content=system_message),\n",
        "                  HumanMessage(content=\"Tengo un perro y vivo en Medellín, Colombia\")]},\n",
        "    stream_mode=\"messages\",\n",
        "):\n",
        "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
        "        print(text, end=\"\")"
      ],
      "metadata": {
        "id": "FrWSQhmuXlhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "\n",
        "\n",
        "*   https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent\n",
        "*   https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.StreamMode\n",
        "\n"
      ],
      "metadata": {
        "id": "yqn5-aBBlrmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "p9_IaxBglpUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}