{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOem60ilpD/r41E01UG+cFg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_agentic_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dial√©ktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este peque√±o tutorial pertenece al curso de RAG y agentes con LangChain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecuci√≥n de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librer√≠as"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librer√≠as.\n",
        "!pip install langchain==0.3.21\n",
        "!pip install langchain-community==0.3.20\n",
        "!pip install beautifulsoup4==4.13.3\n",
        "!pip install langgraph==0.3.31\n",
        "!pip install duckduckgo-search==8.0.0\n",
        "!pip install tiktoken==0.9.0\n",
        "!pip install pypdf==5.4.0\n",
        "!pip install langchain-huggingface==0.1.2\n",
        "!pip install langchain_deepseek==0.1.2"
      ],
      "metadata": {
        "id": "8U_GtE_0tuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "# Se importan las librer√≠as.\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "from typing import Any\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
        "from langchain_community.tools import DuckDuckGoSearchResults\n",
        "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.schema import BaseChatMessageHistory, BaseMessage\n",
        "from google.colab import userdata\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "import bs4\n",
        "import pandas as pd\n",
        "from uuid import uuid4\n",
        "\n",
        "# Filtro para advertencias.\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# A√±adiendo un RAG como herramienta a un agente"
      ],
      "metadata": {
        "id": "4lxITC5Y8I9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga la informaci√≥n desde distintas fuentes\n",
        "web_loader = WebBaseLoader(web_paths=[\"https://dialektico.com/cama-ultra-lujosa-para-gatos-dialektiroyal-comfort/\"])\n",
        "documents = []\n",
        "\n",
        "for doc in os.listdir('documents'):\n",
        "  pdf_loader = PyPDFLoader('documents/'+ doc)\n",
        "  async for page in pdf_loader.alazy_load():\n",
        "      documents.append(page)\n",
        "\n",
        "async for doc in web_loader.alazy_load():\n",
        "    documents.append(doc)"
      ],
      "metadata": {
        "id": "pUWlq-Zpm4jr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cantidad de documentos.\n",
        "len(documents)"
      ],
      "metadata": {
        "id": "Hqwqly6fm7Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prepara el algoritmo de embeddings a utilizar.\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "id": "A9czCxAmny0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea vector store en memoria para almacenar vectores.\n",
        "vector_store = InMemoryVectorStore(embedding=embeddings_model)\n",
        "\n",
        "# Se instancia el CharacterTextSplitter.\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name=\"cl100k_base\", chunk_size=1000, chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Se divide el texto de los documentos utilizando el tokenizador tiktoken.\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# Se almacenan los vectores.\n",
        "vector_store.add_documents(documents=chunks, ids=[str(uuid4()) for _ in range(len(chunks))])"
      ],
      "metadata": {
        "id": "lvs_9yfYn5-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se traen documentos con mayor similaridad.\n",
        "question = \"¬øCu√°l es el precio del su√©ter t√©rmico de felpa para perros?\"\n",
        "retrieved_docs = vector_store.similarity_search(question, k=5)\n",
        "docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)"
      ],
      "metadata": {
        "id": "Ejn-i4p8oYdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs_content"
      ],
      "metadata": {
        "id": "aInZjCvaqdpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def buscar_producto_en_vectorstore(prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Realiza una b√∫squeda sem√°ntica en una base de datos vectorial para recuperar\n",
        "    documentos relacionados con un producto, bas√°ndose en el contenido del prompt.\n",
        "\n",
        "    El objetivo es obtener informaci√≥n √∫til sobre productos espec√≠ficos\n",
        "    (como caracter√≠sticas, materiales, tallas, precio, etc.) almacenada en una\n",
        "    base vectorial de documentos.\n",
        "\n",
        "    Args:\n",
        "        * prompt (str): La consulta o pregunta sobre un producto, como \"¬øQu√©\n",
        "        caracter√≠sticas tienen la camiseta de lino para gatos y la\n",
        "        camisa transpirable de mallas para perros?\".\n",
        "\n",
        "    Returns:\n",
        "        str: contenidos (`page_content`) de los documentos\n",
        "        m√°s relevantes encontrados.\n",
        "\n",
        "    Example:\n",
        "        >>> buscar_producto_en_vectorstore(\n",
        "                \"¬øCu√°les son las caracter√≠sticas ¬øQu√© caracter√≠sticas tienen la\n",
        "                camiseta de lino para gatos y la camisa transpirable de mallas\n",
        "                para perros??\"\n",
        "            )\n",
        "        'Descripci√≥n: Su√©ter grueso y suave...', 'Colores: Gris claro, Vino...'\n",
        "    \"\"\"\n",
        "    # Realizar la b√∫squeda sem√°ntica\n",
        "    retrieved_docs = vector_store.similarity_search(prompt, k=5)\n",
        "\n",
        "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "    # Extraer y retornar el contenido de los documentos\n",
        "    return docs_content\n",
        "\n"
      ],
      "metadata": {
        "id": "Q1tXoBZWaOu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"¬øCu√°l es el precio del su√©ter t√©rmico de felpa para perros?\"\n",
        "\n",
        "buscar_producto_en_vectorstore(prompt)"
      ],
      "metadata": {
        "id": "2SDg4X-ftXQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definimos la herramienta del buscador web.\n",
        "search = DuckDuckGoSearchResults(max_results=5, description=\"\"\"Herramienta que\n",
        "puede ser utilizada para buscar informaci√≥n en internet, se puede buscar el\n",
        "clima del d√≠a actual, por ejemplo: ¬øcu√°l es la temperatura en Guadalajara\n",
        "Jalisco el d√≠a de hoy?\"\"\")\n",
        "\n",
        "def obtener_prendas_para_mascota(ruta_csv: str, animal: str, temperatura_aprox: float) -> list[str]:\n",
        "    \"\"\"\n",
        "    Filtra una tabla CSV de prendas para mascotas y devuelve aquellas adecuadas\n",
        "    seg√∫n el tipo de animal (perro o gato) y la temperatura actual.\n",
        "\n",
        "    La funci√≥n clasifica la temperatura en una de tres categor√≠as:\n",
        "        - 'fr√≠o': temperatura menor a 15¬∞C\n",
        "        - 'templado': temperatura entre 15¬∞C y 25¬∞C (inclusive)\n",
        "        - 'caluroso': temperatura mayor a 25¬∞C\n",
        "\n",
        "    Luego, filtra las prendas que coincidan con la clasificaci√≥n de temperatura y el animal especificado.\n",
        "\n",
        "    Args:\n",
        "        ruta_csv (str): Ruta al archivo CSV que contiene la tabla de prendas.\n",
        "        animal (str): Tipo de mascota, solo puede ser: 'gato' o 'perro'.\n",
        "        temperatura_actual (float): Temperatura en grados Celsius.\n",
        "\n",
        "    Returns:\n",
        "        list[str]: Lista de nombres de prendas recomendadas para el animal y clima dados.\n",
        "\n",
        "    Raises:\n",
        "        FileNotFoundError: Si no se encuentra el archivo CSV en la ruta especificada.\n",
        "        ValueError: Si el tipo de animal no est√° presente en la tabla.\n",
        "\n",
        "    Example:\n",
        "        >>> obtener_prendas_para_mascota('prendas_mascotas.csv', 'perro', 10)\n",
        "        ['chamarra acolchada impermeable', 'su√©ter t√©rmico de felpa']\n",
        "    \"\"\"\n",
        "    # Cargar la tabla\n",
        "    df = pd.read_csv(ruta_csv)\n",
        "\n",
        "    # Clasificar la temperatura\n",
        "    if temperatura_aprox < 15:\n",
        "        clasificacion_temp = 'fr√≠o'\n",
        "    elif 15 <= temperatura_aprox <= 25:\n",
        "        clasificacion_temp = 'templado'\n",
        "    else:\n",
        "        clasificacion_temp = 'caluroso'\n",
        "\n",
        "    # Verificar si el animal est√° en el dataset\n",
        "    if animal.lower() not in df['animal'].str.lower().unique():\n",
        "        raise ValueError(f\"Animal '{animal}' no encontrado en la tabla.\")\n",
        "\n",
        "    # Filtrar seg√∫n clasificaci√≥n de temperatura y animal\n",
        "    prendas_filtradas = df[\n",
        "        (df['temperatura'] == clasificacion_temp) &\n",
        "        (df['animal'].str.lower() == animal.lower())\n",
        "    ]\n",
        "\n",
        "    return prendas_filtradas['nombre_prenda'].tolist()"
      ],
      "metadata": {
        "id": "hIuxRdvTB71L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se a√±ade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "# Se define el modelo a utilizar y a√±aden valores de par√°metros.\n",
        "model = ChatDeepSeek(\n",
        "      model=\"deepseek-chat\",\n",
        "      temperature=0,\n",
        "      max_tokens=300\n",
        "      )"
      ],
      "metadata": {
        "id": "ksza_EkW9vTq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creando multiRAG ag√©ntico con LangGraph"
      ],
      "metadata": {
        "id": "GlY5WRSfcehr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora utilizaremos `create_react_agent` para crear un agente que utilice estas herramientaS.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/04/graph_lc.png\" width=\"200\" /></center>\n",
        "\n"
      ],
      "metadata": {
        "id": "33lubd0eab2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para crear un multiRag ag√©ntico a√±adiremos una nueva herramienta a la lista y recrearemos el agente.\n",
        "\n",
        "Lo haremos para crear un agente que atienda a una tienda electr√≥nica de accesorios para mascotas.\n",
        "\n",
        "El agente debe hacer lo siguiente:\n",
        "\n",
        "\n",
        "\n",
        "*   Investigar la temperatura de la ciudad donde vive el cliente.\n",
        "*   Conociendo la temperatura, y el tipo de mascota del cliente (perro o gato), extraer informaci√≥n de los productos que puede ofrecer de un CSV.\n",
        "* Dar la informaci√≥n al cliente.\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/04/Diagrama_agente_2.drawio.png\" width=\"1000\" /></center>\n"
      ],
      "metadata": {
        "id": "dldv6GMAdHiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el agente con herramientas nuevas.\n",
        "tools = [search, obtener_prendas_para_mascota, buscar_producto_en_vectorstore]\n",
        "agent_executor = create_react_agent(model, tools)\n",
        "\n",
        "# Se a√±aden instrucciones.\n",
        "system_message = \"\"\"Eres un asistente de una tienda en l√≠nea que vende productos\n",
        "        para mascotas. El cliente te dir√° qu√© mascota tiene (perro o gato) y en\n",
        "        qu√© ciudad vivo, y t√∫ debes de seguir los siguientes pasos:\n",
        "        - Debes de utilizar la herramienta search para obtener la temperatura\n",
        "        aproximada de la ciudad donde vive, colocando en el buscador:\n",
        "        cu√°l es el clima actual en {ciudad del cliente}.\n",
        "        - Utilizando la informaci√≥n del buscador, utilizar√°s la herramienta\n",
        "        obtener_prendas_para_mascota, a√±adiendo los argumentos correspondientes,\n",
        "        donde el csv con la informaci√≥n est√° en /content/productos.csv, y a√±ades\n",
        "        tipo de animal y temperatura aproximada para obtener los datos.\n",
        "        - Utilizando estos datos, utiliza la herramienta buscar_producto_en_vectorstore,\n",
        "        a√±ade como argumento un prompt que solicite informaci√≥n de los productos\n",
        "        que obtuviste con la herramienta obtener_prendas_para_mascota.\n",
        "        - Finalmente, utiliza la informaci√≥n que obtuviste de la herramienta\n",
        "        buscar_producto_en_vectorstore para dar la informaci√≥n al cliente de los\n",
        "        productos que le puedes ofrecer, dile los nombres de los productos, su\n",
        "        descrip√≠ci√≥n, colores, tallas y precio, no olvides ser amable.\n",
        "        Utiliza pocas oraciones y mant√©n la respuesta lo m√°s concisa posible.\n",
        "        \"\"\"\n"
      ],
      "metadata": {
        "id": "qLJ0wpnzUXAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza el agente haciendo stream en la respuesta.\n",
        "for step, metadata in agent_executor.stream(\n",
        "    {\"messages\": [SystemMessage(\n",
        "        content=system_message),\n",
        "                  HumanMessage(content=\"¬øHola, vivo en Manchester, Inglaterra, qu√© ropa tienes para gato?\")]},\n",
        "    stream_mode=\"messages\",\n",
        "):\n",
        "    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
        "        print(text, end=\"\")"
      ],
      "metadata": {
        "id": "FrWSQhmuXlhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from langchain.schema import SystemMessage, HumanMessage\n",
        "from uuid import uuid4\n",
        "from typing import Any\n",
        "\n",
        "def agentic_multirag(agent_executor: Any, system_message: str) -> None:\n",
        "    session_id = str(uuid4())\n",
        "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
        "\n",
        "    textarea = widgets.Textarea(\n",
        "        value='',\n",
        "        placeholder='Escribe tu pregunta aqu√≠...',\n",
        "        description='Pregunta:',\n",
        "        layout=widgets.Layout(width='100%', height='100px')\n",
        "    )\n",
        "\n",
        "    enviar_button = widgets.Button(description=\"Enviar\", button_style='primary')\n",
        "    output = widgets.Output()\n",
        "\n",
        "    def on_submit(_):\n",
        "        user_question = textarea.value.strip()\n",
        "        textarea.value = ''\n",
        "        output.clear_output()\n",
        "\n",
        "        if user_question.lower() in ('salir', 'exit', 'quit'):\n",
        "            with output:\n",
        "                display(Markdown(\"üö™ **Saliendo del chat. ¬°Hasta luego!**\"))\n",
        "            return\n",
        "\n",
        "        full_response = \"\"\n",
        "\n",
        "        with output:\n",
        "            try:\n",
        "                for step, metadata in agent_executor.stream(\n",
        "                    {\n",
        "                        \"messages\": [\n",
        "                            SystemMessage(content=system_message),\n",
        "                            HumanMessage(content=user_question)\n",
        "                        ]\n",
        "                    },\n",
        "                    config,\n",
        "                    stream_mode=\"messages\",\n",
        "                ):\n",
        "                    if metadata[\"langgraph_node\"] == \"agent\" and (text := step.text()):\n",
        "                        full_response += text\n",
        "\n",
        "                # Mostrar la respuesta completa como Markdown\n",
        "                display(Markdown(full_response))\n",
        "                display(Markdown(\"\\nüìù *Escribe otra pregunta (o 'salir' para terminar):*\"))\n",
        "\n",
        "            except Exception as e:\n",
        "                display(Markdown(f\"\\n‚ùó **Error:** {e}\"))\n",
        "\n",
        "    enviar_button.on_click(on_submit)\n",
        "    display(widgets.VBox([textarea, enviar_button, output]))\n"
      ],
      "metadata": {
        "id": "Pd3DFlYM2YvS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "memory = MemorySaver()\n",
        "\n",
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "agentic_multirag(agent_executor, system_message)"
      ],
      "metadata": {
        "id": "-mNYqA9n3TRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "M√°s informaci√≥n en:\n",
        "\n",
        "\n",
        "*   https://langchain-ai.github.io/langgraph/reference/prebuilt/#langgraph.prebuilt.chat_agent_executor.create_react_agent\n",
        "*   https://langchain-ai.github.io/langgraph/reference/types/#langgraph.types.StreamMode\n",
        "\n"
      ],
      "metadata": {
        "id": "yqn5-aBBlrmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "p9_IaxBglpUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices ¬© 2025 by Daniel Antonio Garc√≠a Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}