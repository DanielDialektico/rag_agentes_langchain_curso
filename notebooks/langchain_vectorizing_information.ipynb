{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN7+k8wRZole6mfTMJhT0kn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_vectorizing_information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG con Langchain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librerías.\n",
        "!pip install langchain-pinecone==0.2.4\n",
        "!pip install langchain==0.3.21\n",
        "!pip install langchain-community==0.3.20\n",
        "!pip install beautifulsoup4==4.13.3\n",
        "!pip install tiktoken==0.9.0\n",
        "!pip install pypdf==5.4.0\n",
        "!pip install pinecone==6.0.2\n",
        "!pip install langchain-huggingface==0.1.2"
      ],
      "metadata": {
        "id": "8U_GtE_0tuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "# Se importan las librerías.\n",
        "import os\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "from langchain_pinecone import PineconeVectorStore\n",
        "import bs4\n",
        "from google.colab import userdata\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from uuid import uuid4\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorizar información con LangChain"
      ],
      "metadata": {
        "id": "7HnRYF3bHbYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los **embeddings** crean una **representación vectoria**l de un fragmento de texto. Esto es útil porque nos permite trabajar con el texto en el espacio vectorial y hacer cosas como **búsqueda semántica**, donde buscamos fragmentos de texto que sean más similares dentro de ese espacio.\n",
        "\n",
        "La clase base `Embeddings` en LangChain proporciona dos métodos: uno para generar embeddings de documentos y otro para consultas. El primero, .`embed_documents`, toma como entrada múltiples textos, mientras que el segundo, .`embed_query`, toma un único texto.\n",
        "\n",
        "La clase **Embeddings** es una clase diseñada para interactuar con modelos de embeddings de texto. Existen muchos proveedores de modelos de embeddings (OpenAI, Cohere, Hugging Face, etc.), y esta clase está pensada para ofrecer una interfaz estándar para todos ellos."
      ],
      "metadata": {
        "id": "YCiYm2pJ_uJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un paso fundamental en un sistema RAG es la carga y división de documentos en fragmentos informativos, los cuales serán posteriormente vectorizados y almacenados en una base de datos.\n",
        "\n",
        "Seguiremos los siguientes pasos:\n",
        "\n",
        "**Cargar**: Cargar documentos para su división. Esto se hace con Document Loaders (cargadores de documentos).\n",
        "**Dividir**: Utizaremos Text Splitters (divisores de texto), los cuales dividen documentos grandes en fragmentos más pequeños. Esto es útil tanto para indexar los datos como para pasarlos a un modelo, ya que los fragmentos grandes son más difíciles de buscar y no caben en la ventana de contexto limitada de un modelo."
      ],
      "metadata": {
        "id": "PIbYz1WkP3Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vectorizando un texto con Hugging Face"
      ],
      "metadata": {
        "id": "Hhycfl7t_7FD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prepara el algoritmo a utilizar.\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "id": "Jyya8-dt_6yz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Me gusta commer pizza.\"\n",
        "query_result = embeddings_model.embed_query(text)\n",
        "query_result[:3]"
      ],
      "metadata": {
        "id": "xVpwWRgEAg3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://python.langchain.com/docs/integrations/text_embedding/huggingfacehub/"
      ],
      "metadata": {
        "id": "Z463iAWzCv8L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "mvtv22r-A7tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Vectorizando documentos"
      ],
      "metadata": {
        "id": "1xleMCKrAzsj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilizaremos el código visto en la [lección anterior](https://colab.research.google.com/drive/1rG_KCvFO6DZN56GruFwESlaxhU09TnSi#scrollTo=8U_GtE_0tuGp), donde cargamos y dividimos información en unidades más pequeñas que llamaremos \"documentos\"."
      ],
      "metadata": {
        "id": "JebmMnH5A9Oj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga el documento PDF.\n",
        "loader = PyPDFLoader('/content/Aviso_de_privacidad.pdf')\n",
        "pdf_pages = []\n",
        "async for page in loader.alazy_load():\n",
        "    pdf_pages.append(page)\n",
        "\n",
        "# Se carga la información de una página web.\n",
        "\n",
        "page_url = \"https://dialektico.com/cama-ultra-lujosa-para-gatos-dialektiroyal-comfort/\"\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[page_url])\n",
        "web_info = []\n",
        "async for doc in loader.alazy_load():\n",
        "    web_info.append(doc)"
      ],
      "metadata": {
        "id": "hIuxRdvTB71L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Se generan los fragmentos (documentos a vectorizar)"
      ],
      "metadata": {
        "id": "uZv6VOFWCVzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instancia el CharacterTextSplitter.\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name=\"cl100k_base\", chunk_size=1000, chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Se divide el texto utilizando el tokenizador tiktoken.\n",
        "pdf_documents = text_splitter.split_documents(pdf_pages)\n",
        "web_documents = text_splitter.split_documents(web_info)"
      ],
      "metadata": {
        "id": "TCiSMQ4wCyzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://python.langchain.com/docs/concepts/text_splitters/"
      ],
      "metadata": {
        "id": "nJaVkNUfM4hz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se unen ambos conjuntos de documentos.\n",
        "all_documents = pdf_documents + web_documents\n",
        "\n",
        "# Se extrae sel contenido de texto de cada documento.\n",
        "all_texts = [doc.page_content for doc in all_documents]\n",
        "\n",
        "all_texts[0]"
      ],
      "metadata": {
        "id": "JzAL9WqaE1gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_texts)"
      ],
      "metadata": {
        "id": "fbB_KgGtGieM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = embeddings_model.embed_documents(all_texts)"
      ],
      "metadata": {
        "id": "RJO_iM0bD8Pr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings), len(embeddings[0])"
      ],
      "metadata": {
        "id": "J29kzL_-GYU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings[0][:10]"
      ],
      "metadata": {
        "id": "oqZSxwgLGoJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "* https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\n",
        "* https://python.langchain.com/docs/how_to/embed_text/"
      ],
      "metadata": {
        "id": "jFs3AhCKGyDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "OldSm4S81Dds"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Almacenando vectores con LangChain"
      ],
      "metadata": {
        "id": "RaSktThP0wXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LangChain** proporciona una interfaz estándar para trabajar con **bases de datos vectoriales** (**vector stores**), lo que permite a los usuarios cambiar fácilmente entre distintas implementaciones.\n",
        "\n",
        "La interfaz consiste en métodos básicos para **escribir**, **eliminar** y **buscar** documentos dentro del almacén vectorial.\n",
        "\n",
        "Los métodos clave son:\n",
        "\n",
        "`add_documents`: Agrega una lista de textos al almacén vectorial.\n",
        "\n",
        "`delete`: Elimina una lista de documentos del almacén vectorial.\n",
        "\n",
        "`similarity_search`: Busca documentos similares a una consulta dada.\n"
      ],
      "metadata": {
        "id": "ByAR9nS31HGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Almacenando vectores en memoria interna con LangChain"
      ],
      "metadata": {
        "id": "_Y6rahY01ZqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea vector store en memoria para almacenar vectores.\n",
        "vector_store = InMemoryVectorStore(embedding=embeddings_model)\n",
        "\n",
        "# Se almacenan los vectores.\n",
        "vector_store.add_documents(documents=all_documents)"
      ],
      "metadata": {
        "id": "9MQZpQY11X0k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "IxeT_AvA3ERH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea vector store en memoria para almacenar vectores.\n",
        "vector_store = InMemoryVectorStore(embedding=embeddings_model)\n",
        "\n",
        "vector_store.add_documents(documents=all_documents, ids=[f\"doc_{i+1}\" for i in range(len(all_documents))])"
      ],
      "metadata": {
        "id": "2axun5Aw3aLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.store['doc_1']"
      ],
      "metadata": {
        "id": "g2BdF_CB5FxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Eliminando vectores"
      ],
      "metadata": {
        "id": "lbYPuFUg3-as"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.delete(ids=[\"doc_1\", \"doc_2\"])"
      ],
      "metadata": {
        "id": "p7qaTH_a2iP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.store['doc_1']"
      ],
      "metadata": {
        "id": "LenmldB84FjE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://python.langchain.com/api_reference/core/vectorstores/langchain_core.vectorstores.in_memory.InMemoryVectorStore.html"
      ],
      "metadata": {
        "id": "hUqzFAbU6egF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "5DXdPe3f6g0N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buscando vectores"
      ],
      "metadata": {
        "id": "goGL2L535a79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Los vector stores (almacenes vectoriales o bases de datos vectoriales) generan embeddings y almacenan los documentos que se les agregan. Si se proporciona una consulta (query), el almacén vectorial genera el embedding de esa consulta, realiza una búsqueda por similitud sobre los documentos ya embebidos y devuelve los más similares.\n",
        "\n",
        "Esto implica dos conceptos importantes:\n",
        "\n",
        "* Debe existir una forma de medir la similitud entre la consulta y cada documento embebido.\n",
        "* Debe haber un algoritmo eficiente para realizar esta búsqueda de similitud sobre todos los documentos embebidos.\n",
        "\n",
        "## Métricas de similitud\n",
        "Una ventaja clave de los vectores es que pueden compararse mediante operaciones matemáticas simples:\n",
        "\n",
        "* Similitud del coseno (Cosine Similarity): Mide el coseno del ángulo entre dos vectores.\n",
        "* Distancia euclidiana (Euclidean Distance): Mide la distancia en línea recta entre dos puntos.\n",
        "* Producto punto (Dot Product): Mide la proyección de un vector sobre otro."
      ],
      "metadata": {
        "id": "BuCpaQUi5v2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea vector store en memoria para almacenar vectores.\n",
        "vector_store = InMemoryVectorStore(embedding=embeddings_model)\n",
        "\n",
        "# Se almacenan los vectores.\n",
        "vector_store.add_documents(documents=all_documents, ids=[f\"doc_{i+1}\" for i in range(len(all_documents))])\n",
        "\n",
        "query = \"¿Qué incluye la cama ultralujosa para gatos?\"\n",
        "docs = vector_store.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "7aeucX8D5TCU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "WCMAvcCxF0FW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"¿Por qué la página web DialektiPet utiliza cookies?\"\n",
        "docs = vector_store.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "5Ib_mzlPGJAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "34d56ToqGSRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://python.langchain.com/docs/concepts/vectorstores/"
      ],
      "metadata": {
        "id": "Qtgu1TejGjmv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "U9Y6TNb4IMR3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utilizando un vector store con Pinecone"
      ],
      "metadata": {
        "id": "TtLdGPp6IPSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para poder almacenar los vectores en servicios externos, se puede atender a todas las posibles integraciones de Langchain. En este caso, utilizaremos Pinecone, en donde puedes crear una cuenta gratuita y almacenar un cierto número de vectores con información relacionada.\n",
        "\n",
        "Para crear tu cuenta, ingresa a aquí: https://www.pinecone.io/"
      ],
      "metadata": {
        "id": "ZSZTYQ_RIUsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"PINECONE_API_KEY\"] = userdata.get('PINECONE_API_KEY')"
      ],
      "metadata": {
        "id": "-fwBNF8gIOFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(embeddings[0])"
      ],
      "metadata": {
        "id": "rsldV8kfLVEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pc = Pinecone()\n",
        "index_name = 'test-langchain'\n",
        "\n",
        "pc.create_index(\n",
        "        name='test-langchain',\n",
        "        dimension=384,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
        "    )\n",
        "\n",
        "index = pc.Index(index_name)"
      ],
      "metadata": {
        "id": "vwVX7pXKLLw3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store = PineconeVectorStore(index=index, embedding=embeddings_model)"
      ],
      "metadata": {
        "id": "dV5d8pzTR1sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(all_documents)"
      ],
      "metadata": {
        "id": "bKM5qy-qe9-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Indexando documentos"
      ],
      "metadata": {
        "id": "IZ5HIc6Ahd_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.add_documents(documents=all_documents, ids=[str(uuid4()) for _ in range(len(all_documents))])"
      ],
      "metadata": {
        "id": "0J4pI80ESMfZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"¿Qué incluye la cama ultralujosa para gatos?\"\n",
        "docs = vector_store.similarity_search(query, k=3)"
      ],
      "metadata": {
        "id": "eRmrtPMtTwxS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "fHEZunUAHee9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Buscando vectores con filtro de metadatos"
      ],
      "metadata": {
        "id": "HtbEpEWjGl3e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store.store['doc_11']['metadata']"
      ],
      "metadata": {
        "id": "CrYlB0vrGsjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"¿Qué incluye la cama ultralujosa para gatos?\"\n",
        "docs = vector_store.similarity_search(query, k=3, filter={\"source\": \"https://dialektico.com/cama-ultra-lujosa-para-gatos-dialektiroyal-comfort/\"})"
      ],
      "metadata": {
        "id": "WzW4kUDjGlBu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "*   https://python.langchain.com/docs/integrations/vectorstores/pinecone/\n",
        "*   https://python.langchain.com/docs/concepts/vectorstores/\n",
        "\n"
      ],
      "metadata": {
        "id": "kDj-g4rHHhDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}