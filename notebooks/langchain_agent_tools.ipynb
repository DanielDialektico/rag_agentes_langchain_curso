{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyONb/AHk7FeWxuRY2oUfWT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_agent_tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG y agentes con LangChain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.20\n",
        "!pip install langchain_deepseek==0.1.2\n",
        "!pip install langgraph==0.3.31"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "from langchain_core.messages import  HumanMessage, AIMessage\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from google.colab import userdata\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "myaORM7lJxBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se añade valor de API key mediante un secreto"
      ],
      "metadata": {
        "id": "Uslpy62GOh3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "HitB-RQEOiqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se declara el modelo a utilizar"
      ],
      "metadata": {
        "id": "2xjS3Gb7Ov6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se define el modelo y añaden valores de parámetros.\n",
        "model = ChatDeepSeek(\n",
        "      model=\"deepseek-chat\",\n",
        "      temperature=0,\n",
        "      max_tokens=100\n",
        "      )"
      ],
      "metadata": {
        "id": "Vn5osNj5OxgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Herramientas de apoyo para los modelos"
      ],
      "metadata": {
        "id": "7HnRYF3bHbYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "​En LangChain, una herramienta (tool) es una función de Python asociada a un esquema que define su nombre, descripción y los argumentos esperados. Estas herramientas permiten que modelos de lenguaje, cadenas o agentes interactúen con el mundo exterior, ejecutando acciones específicas o accediendo a información externa."
      ],
      "metadata": {
        "id": "fu24dlP7HjqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creando una herramienta con LangChain"
      ],
      "metadata": {
        "id": "Vd8YgprWBG8m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Se crea una función para ser utilizada como herramienta.\n",
        "\n",
        "def dialektinumero(number_1: int, number_2: int) -> float:\n",
        "    \"\"\"Crea un dialektinúmero mediante una operación específica\n",
        "    con dos números.\n",
        "\n",
        "    Args:\n",
        "        number_1: primer número de entrada.\n",
        "        number_2: segundo número de entrada.\n",
        "\n",
        "    Returns:\n",
        "        El resultado de la operación.\n",
        "    \"\"\"\n",
        "    result = (number_1 + number_2 - 1.5)*3.14\n",
        "    return result"
      ],
      "metadata": {
        "id": "BePVexWAH-8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialektinumero(2,8)"
      ],
      "metadata": {
        "id": "6rKL6vky-Y7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "goKh4MkLWiW1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLM utilizando la herramienta (agente)"
      ],
      "metadata": {
        "id": "9rgpiqAiWX01"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se pasa una lista de herramientas a la LLM mediante `.bind_tools`."
      ],
      "metadata": {
        "id": "m_l6ACTFXWI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la función a una lista de herramientas.\n",
        "tools = [dialektinumero]\n",
        "\n",
        "# Se añade la función como herramienta del LLM.\n",
        "model_with_tools = model.bind_tools(tools)\n",
        "\n",
        "# Se imprime la configuración.\n",
        "model_with_tools"
      ],
      "metadata": {
        "id": "0mqFkHH-H2QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ejecutamos un mensaje que no requiera el uso de la herramienta."
      ],
      "metadata": {
        "id": "L0kGPW-uY-Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se genera una respuesta y se imprime su contenido.\n",
        "response = model_with_tools.invoke([HumanMessage(content=\"Hola!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "id": "WWNynBqhXgzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se obtienen los detalles.\n",
        "response"
      ],
      "metadata": {
        "id": "ep52SljdZknz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Probamos con un prompt que requiera el uso de la herramienta."
      ],
      "metadata": {
        "id": "90yFM-VHZEOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"¿Cuáles es el dialektinúmero de 5 y 10?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "id": "0p3LHn_CZHg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "favNHralBOkX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando al agente"
      ],
      "metadata": {
        "id": "O8f5YNj-BMy3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora que se ha definido una herramienta y el modelo de lenguaje (LLM), podemos crear un agente. Usaremos LangGraph para construir el agente.\n",
        "\n",
        "Ahora podemos inicializar el agente con el LLM y las herramientas.\n",
        "\n",
        "**Nota:** que estamos pasando el modelo, no model_with_tools. Esto se debe a que create_react_agent llamará a .bind_tools por nosotros internamente."
      ],
      "metadata": {
        "id": "KX0A3LTQZ0Pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea el agente, pasando el modelo y las herramientas definidas.\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "YyTcXKe5RWfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se pasa un prompt de entrada al agente.\n",
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"¿Cuáles es el dialektinúmero de 5 y 10?\")]}\n",
        ")\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "id": "xTO_PvD1RiZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for step in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"¿Cuáles es el dialektinúmero de 5 y 10?\")]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "id": "koyrexmVR0x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filtrar el mensaje de tipo AIMessage (aunque usualmente es el último)\n",
        "ai_messages = [m for m in response[\"messages\"] if isinstance(m, AIMessage)]\n",
        "print(ai_messages[-1].content)"
      ],
      "metadata": {
        "id": "tRf4GuFvSFYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "097v10PjAa5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Herramientas disponibles por LangChain: https://python.langchain.com/docs/integrations/tools/\n",
        "\n",
        "Más información en: https://python.langchain.com/docs/concepts/tools/"
      ],
      "metadata": {
        "id": "81-9Vq9-AeBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "IxeT_AvA3ERH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}