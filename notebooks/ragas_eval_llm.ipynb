{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrgCv5r1U5ACHvzBHzb4Ih",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/ragas_eval_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG y agentes con LangChain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se instalan las librerías.\n",
        "!pip install langchain==0.3.21\n",
        "!pip install langchain-community==0.3.20\n",
        "!pip install beautifulsoup4==4.13.3\n",
        "!pip install tiktoken==0.9.0\n",
        "!pip install pypdf==5.4.0\n",
        "!pip install langchain-huggingface==0.1.2\n",
        "!pip install langchain_deepseek==0.1.2\n",
        "!pip install ragas==0.2.15"
      ],
      "metadata": {
        "id": "8U_GtE_0tuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "# Se importan las librerías.\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "import bs4\n",
        "from ragas import EvaluationDataset, evaluate\n",
        "from ragas.llms import LangchainLLMWrapper\n",
        "from ragas.metrics import LLMContextRecall, Faithfulness, SemanticSimilarity, FactualCorrectness\n",
        "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
        "from google.colab import userdata\n",
        "from uuid import uuid4\n",
        "from IPython.display import display, HTML\n",
        "from pydantic import BaseModel, Field\n",
        "from typing import List\n",
        "\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se declaran los modelos a utilizar"
      ],
      "metadata": {
        "id": "4lxITC5Y8I9o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY')\n",
        "\n",
        "model = ChatDeepSeek(\n",
        "      model=\"deepseek-chat\",\n",
        "      temperature=0,\n",
        "      max_tokens=1000\n",
        "      )"
      ],
      "metadata": {
        "id": "F7kpoUUJweql"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prepara el algoritmo de embeddings a utilizar.\n",
        "embeddings_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")"
      ],
      "metadata": {
        "id": "wkG3l9qc5_Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "6qBccYueXpyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se indexan documentos vectorizados de forma local"
      ],
      "metadata": {
        "id": "eigBCJLYXrWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga la información desde distintas fuentes\n",
        "web_loader = WebBaseLoader(web_paths=[\"https://dialektico.com/cama-ultra-lujosa-para-gatos-dialektiroyal-comfort/\"])\n",
        "documents = []\n",
        "\n",
        "for doc in os.listdir('documents'):\n",
        "  pdf_loader = PyPDFLoader('documents/'+ doc)\n",
        "  async for page in pdf_loader.alazy_load():\n",
        "      documents.append(page)\n",
        "\n",
        "async for doc in web_loader.alazy_load():\n",
        "    documents.append(doc)\n",
        "\n",
        "# Se crea vector store en memoria para almacenar vectores.\n",
        "vector_store = InMemoryVectorStore(embedding=embeddings_model)\n",
        "\n",
        "# Se instancia el CharacterTextSplitter.\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name=\"cl100k_base\", chunk_size=1000, chunk_overlap=200\n",
        ")\n",
        "\n",
        "# Se divide el texto de los documentos utilizando el tokenizador tiktoken.\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "# Se almacenan los vectores.\n",
        "vector_store.add_documents(documents=chunks, ids=[str(uuid4()) for _ in range(len(chunks))])"
      ],
      "metadata": {
        "id": "_g6orMRz5o6T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "47yonehPX3RJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se crear el flujo de respuestas con RAG"
      ],
      "metadata": {
        "id": "xN1Wr38gX0oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rag_answer(user_prompt: str):\n",
        "  # Se crea template para RAG.\n",
        "  prompt_template = \"\"\"Utiliza los siguientes fragmentos de contexto para responder la\n",
        "  pregunta al final. Si no sabes la respuesta, simplemente di que no la sabes, no\n",
        "  intentes inventar una respuesta.\n",
        "  Utiliza pocas oraciones y mantén la respuesta lo más concisa posible.\n",
        "\n",
        "  CONTEXTO: {context}\n",
        "\n",
        "  PREGUNTA: {question}\n",
        "\n",
        "  Respuesta útil:\"\"\"\n",
        "\n",
        "  # Se recuperan documentos similares.\n",
        "  retrieved_docs = vector_store.similarity_search(user_prompt, k=5)\n",
        "  context = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
        "\n",
        "  # Se añade el contexto al prompt.\n",
        "  prompt = PromptTemplate.from_template(prompt_template)\n",
        "  messages = [\n",
        "    SystemMessage(\"\"\"Eres un asistente virtual de una tienda en línea llamada\n",
        "    dialektipet. Responde a las preguntas del usuario con la información\n",
        "    proporcionada\"\"\"),\n",
        "    HumanMessage(prompt.invoke({\"question\": user_prompt, \"context\": context}).text),\n",
        "]\n",
        "\n",
        "\n",
        "  # Se genera la respuesta.\n",
        "  response = model.invoke(messages).content\n",
        "\n",
        "  return (response, context)"
      ],
      "metadata": {
        "id": "3whgTfuY6MH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se prueba la función.\n",
        "response, context = rag_answer('¿Cómo protegen mi información al realizar un pago?')"
      ],
      "metadata": {
        "id": "ic5poxEcNO4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "t6TXIJzeRkhQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context"
      ],
      "metadata": {
        "id": "ZJ5Wy08LNYXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "LWTssNbqX_1h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluando el RAG con Ragas"
      ],
      "metadata": {
        "id": "cqAfVAMn4yY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para la evaluación de las respuestas del modelo, utilizaremos la librería ragas, la cual nos permite realizar mediciones mediante diferentes métricas."
      ],
      "metadata": {
        "id": "RJeelr7ZYCKZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "\n",
        "\n",
        "*   https://docs.ragas.io/en/stable/\n",
        "*   https://arxiv.org/pdf/2309.15217\n",
        "\n"
      ],
      "metadata": {
        "id": "07QsWq2HYUJJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se crea el conjunto de datos para su evaluación"
      ],
      "metadata": {
        "id": "rhaw0MbIYQXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preguntas del usuari.\n",
        "sample_queries = [\n",
        "    \"¿Cómo protegen mi información al realizar un pago?\",\n",
        "    \"¿Cuál es el precio y las tallas de la playera de algodón para perro?\",\n",
        "    \"¿Qué es Dialektipet?\",\n",
        "    \"¿Qué hago si aún no recibo mi reembolso?\",\n",
        "    \"¿Se aceptan devoluciones de prouductos usados?\"\n",
        "]\n",
        "\n",
        "# Respuestas esperadas.\n",
        "expected_responses = [\n",
        "    \"Nuestras plataformas de Pagos en línea manejan un candado SSL y otros sistemas de seguridad, y sobre todo se tratan de empresas reconocidas con mucha experiencia y excelente reputación en el manejo de información de pagos de cliente en México y en el mundo.\",\n",
        "    \"Las tallas son XS, S, M, L, y el precio es de  $14.99 USD.\",\n",
        "    \"DialektiPet es una tienda en línea especializada en ofrecer los mejores accesorios y productos para mascotas.\",\n",
        "    \"Si aún no recibiste un reembolso, primero revisa de nuevo tu cuenta bancaria. Luego, comunícate con la empresa de tu tarjeta de crédito. [...] puedes contactarnos escribiendo a contacto@dialektipet.com\",\n",
        "    \"No se aceptarán devoluciones de productos usados, abiertos o dañados por el cliente.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "OY29teu8WuxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añaden las respuestas del modelo y el contexto obtenido mediante el RAG.\n",
        "dataset = []\n",
        "\n",
        "for query, reference in zip(sample_queries, expected_responses):\n",
        "    response, context = rag_answer(query)\n",
        "    dataset.append({\n",
        "        \"user_input\": query,\n",
        "        \"retrieved_contexts\": [context],\n",
        "        \"response\": response,\n",
        "        \"reference\": reference,\n",
        "    })\n",
        "\n",
        "evaluation_dataset = EvaluationDataset.from_list(dataset)"
      ],
      "metadata": {
        "id": "uMfrL_2YWwcB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset[0]"
      ],
      "metadata": {
        "id": "GH9pQVUQXAYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "01LjHAxc6gcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación con métricas de Ragas"
      ],
      "metadata": {
        "id": "CMyKfjTkYybR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta evaluación utilizaremos medidas del tipo \"LLM como juez\", donde se utiliza un modelo para determinar la puntuación de una respuesta y/o contexto.\n",
        "\n",
        "Se utilizarán las siguientes tres:\n",
        "\n",
        "\n",
        "*   LLM Context Recall\n",
        "*   Faithfulness\n",
        "*   Factual Correctness\n",
        "\n",
        "Donde:\n",
        "\n",
        "1. **LLM Context Recall**\n",
        "\n",
        "Evalúa qué tanto del contenido de la respuesta de referencia puede encontrarse en los documentos recuperados.\n",
        "\n",
        "Imagina que la respuesta ideal (la referencia) tiene 4 afirmaciones o datos.\n",
        "\n",
        "Si 3 de esas afirmaciones están respaldadas por los documentos recuperados, el context recall es:\n",
        "\n",
        "$\\text{Context Recall} = \\frac{3}{4} = 0.75$\n",
        "\n",
        "Útil para saber si el sistema recuperó el contenido necesario para construir una buena respuesta."
      ],
      "metadata": {
        "id": "Ov_jLg3uY3CB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **Faithfulness**\n",
        "\n",
        "Mide si la respuesta generada realmente se basa en los documentos recuperados.\n",
        "\n",
        "Si la respuesta generada tiene 5 afirmaciones y 4 de ellas están en los documentos recuperados, la puntuación es:\n",
        "\n",
        "$\\text{Faithfulness} = \\frac{4}{5} = 0.8$\n",
        "\n",
        "Ayuda a verificar que el modelo no esté \"inventando\" cosas fuera del contexto recuperado.\n"
      ],
      "metadata": {
        "id": "H-H_55SHameq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. **Factual Correctness**\n",
        "\n",
        "Mide si la respuesta generada coincide con la respuesta correcta (referencia). Aquí se consideran:\n",
        "\n",
        "TP (True Positive): afirmaciones correctas que sí están en la referencia.\n",
        "\n",
        "FP (False Positive): afirmaciones incorrectas (no están en la referencia).\n",
        "\n",
        "FN (False Negative): afirmaciones que faltaron (sí están en la referencia, pero no en la respuesta)."
      ],
      "metadata": {
        "id": "RzM_cXnJapf6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **Semantic Similarity**\n",
        "\n",
        "Se refiere a la evaluación del parecido semántico entre la respuesta generada y la respuesta verdadera (ground truth). Esta evaluación se basa en comparar la respuesta generada con la referencia, y los valores obtenidos oscilan entre 0 y 1. Un puntaje más alto indica una mejor alineación semántica entre ambas respuestas.\n",
        "Esta evaluación utiliza un modelo de embeddings para calcular el puntaje de similitud semántica."
      ],
      "metadata": {
        "id": "q2kJZHns8kYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/"
      ],
      "metadata": {
        "id": "FkQlkyl6asTB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creamos un conjunto de datos de prueba:"
      ],
      "metadata": {
        "id": "f3g2V6KS2Bk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea conjunto de datos de prueba.\n",
        "sample = {\n",
        "    \"user_input\": \"¿Dónde está la torre Eiffel?\",\n",
        "    \"retrieved_contexts\": [\"La torre Eiffel está en París\"],\n",
        "    \"response\": \"La torre Eiffel está en México\",\n",
        "    \"reference\": \"La torre Eiffel está localizada en París.\"\n",
        "}\n",
        "\n",
        "test_dataset_list = [sample]\n",
        "\n",
        "test_dataset_false = EvaluationDataset.from_list(test_dataset_list)"
      ],
      "metadata": {
        "id": "GbUUtVkpd-sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea conjunto de datos de prueba.\n",
        "sample = {\n",
        "    \"user_input\": \"¿Dónde está la torre Eiffel?\",\n",
        "    \"retrieved_contexts\": [\"La torre Eiffel está en París\"],\n",
        "    \"response\": \"La torre Eiffel está en París\",\n",
        "    \"reference\": \"La torre Eiffel está localizada en París.\"\n",
        "}\n",
        "\n",
        "test_dataset_list = [sample]\n",
        "\n",
        "test_dataset_true = EvaluationDataset.from_list(test_dataset_list)"
      ],
      "metadata": {
        "id": "sWFQH4UI_16M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se declara el modelo a utilizar para la evaluación.\n",
        "evaluator_llm = LangchainLLMWrapper(langchain_llm=model)"
      ],
      "metadata": {
        "id": "dxjD_83w--g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Realizamos pruebas con diferentes métricas:"
      ],
      "metadata": {
        "id": "CcPD6Hgl6tyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLM como juez"
      ],
      "metadata": {
        "id": "kI7IS8UdAozM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta la evaluación.\n",
        "result = evaluate(\n",
        "    dataset=test_dataset_false,\n",
        "    metrics=[Faithfulness()],\n",
        "    llm=evaluator_llm,\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "5_qxAK1xd5H7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta la evaluación.\n",
        "result = evaluate(\n",
        "    dataset=test_dataset_true,\n",
        "    metrics=[Faithfulness()],\n",
        "    llm=evaluator_llm,\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "gAl7NgBWABq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diferenciación matemática"
      ],
      "metadata": {
        "id": "IrRytVV4AtPs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade el modelo de emebeddings.\n",
        "embeddings=LangchainEmbeddingsWrapper(embeddings_model)"
      ],
      "metadata": {
        "id": "fIRpd1HqD1jV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta la evaluación.\n",
        "result = evaluate(\n",
        "    dataset=test_dataset_false,\n",
        "    metrics=[SemanticSimilarity()],\n",
        "    embeddings=embeddings,\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "4ZsD6MxuA2fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta la evaluación.\n",
        "result = evaluate(\n",
        "    dataset=test_dataset_true,\n",
        "    metrics=[SemanticSimilarity()],\n",
        "    embeddings=embeddings,\n",
        ")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "id": "MXT_hkEHe9Lz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluación del conjunto de datos creado"
      ],
      "metadata": {
        "id": "IqN6ag6SEmJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se ejecuta la evaluación.\n",
        "result = evaluate(\n",
        "    dataset=evaluation_dataset,\n",
        "    metrics=[LLMContextRecall(), SemanticSimilarity()],\n",
        "    llm=evaluator_llm,\n",
        "    embeddings=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "OBUZ2622XGHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "id": "rfWwcc9HXHQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "\n",
        "\n",
        "*   https://docs.ragas.io/en/stable/howtos/integrations/langchain/#building-a-simple-qa-application\n",
        "*   https://docs.ragas.io/en/latest/references/evaluate/#ragas.evaluation.evaluate\n",
        "\n"
      ],
      "metadata": {
        "id": "yqn5-aBBlrmL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "p9_IaxBglpUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}