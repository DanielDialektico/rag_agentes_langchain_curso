{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPq0JvIgpge6/2dwEH3e1dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_message_history.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG con Langchain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "!pip install langchain==0.3.20\n",
        "!pip install langchain_deepseek==0.1.2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import warnings\n",
        "from operator import itemgetter\n",
        "from typing import List\n",
        "from langchain_deepseek import ChatDeepSeek\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import  SystemMessage, HumanMessage, ToolMessage, BaseMessage, AIMessage\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.runnables import (\n",
        "    RunnableLambda,\n",
        "    ConfigurableFieldSpec,\n",
        "    RunnablePassthrough,\n",
        ")\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.tools import tool\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from google.colab import userdata\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "dRmeNVPjEyOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se añade valor de API key mediante un secreto"
      ],
      "metadata": {
        "id": "Uslpy62GOh3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade la API key como variable de ambiente desde un secreto en Colab.\n",
        "os.environ[\"DEEPSEEK_API_KEY\"] = userdata.get('DEEPSEEK_API_KEY')"
      ],
      "metadata": {
        "id": "HitB-RQEOiqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Se declara el modelo a utilizar"
      ],
      "metadata": {
        "id": "2xjS3Gb7Ov6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se define el modelo y añaden valores de parámetros.\n",
        "model = ChatDeepSeek(\n",
        "      model=\"deepseek-chat\",\n",
        "      temperature=0,\n",
        "      max_tokens=100\n",
        "      )"
      ],
      "metadata": {
        "id": "Vn5osNj5OxgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Añadir memoria al bot"
      ],
      "metadata": {
        "id": "7HnRYF3bHbYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Poder utilizar mensajes pasados como contexto en una conversación, es una característica que permite generar interacciones más naturales con el usuario. LangChain permite realizar esto mediante la adición de esta información al conjunto de preguntas y respuestas."
      ],
      "metadata": {
        "id": "PIbYz1WkP3Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esto, se debe de defnir una clase para el manejor de historiales del chat"
      ],
      "metadata": {
        "id": "TcvsoVYZCPCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class InMemoryHistory(BaseChatMessageHistory, BaseModel):\n",
        "    \"\"\"Implementación de historias de mensajes en memoria local.\"\"\"\n",
        "\n",
        "    messages: List[BaseMessage] = Field(default_factory=list)\n",
        "\n",
        "    def add_messages(self, messages: List[BaseMessage]) -> None:\n",
        "        \"\"\"Añade una lista de mensajes al historial.\"\"\"\n",
        "        self.messages.extend(messages)\n",
        "\n",
        "    def clear(self) -> None:\n",
        "        \"\"\"Limpia el historial de mensajes.\"\"\"\n",
        "        self.messages = []\n",
        "\n",
        "# Se declara la lista donde se almacenarán las conversaciones.\n",
        "store = {}\n",
        "\n",
        "def get_by_session_id(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryHistory()\n",
        "    return store[session_id]"
      ],
      "metadata": {
        "id": "IrHmxZzoGhK5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`store` es un diccionario global que almacena los historiales de chat por ID de sesión.\n",
        "\n",
        "La clave del diccionario es el session_id, y el valor es una instancia de InMemoryHistory.\n",
        "\n",
        "La función `get_by_session_id`:\n",
        "* Recibe un session_id como parámetro.\n",
        "* Si el session_id no existe en store, crea un nuevo historial (InMemoryHistory) y lo almacena en el diccionario.\n",
        "* Devuelve el historial de chat asociado a esa sesión.\n",
        "\n",
        "Se trata de una implementación simple en memoria que no persiste los datos, útil para pruebas o sesiones temporales.\n"
      ],
      "metadata": {
        "id": "JQt6CBfDSQ1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añade un registro al historial.\n",
        "history = get_by_session_id(\"1\")\n",
        "history.add_message(AIMessage(content=\"Hola mundo\"))\n",
        "print(store)"
      ],
      "metadata": {
        "id": "Mw1f8KbPR3qO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "9G8EbFfPTDUO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando cadenas"
      ],
      "metadata": {
        "id": "NFl5mKvhTFEg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un aspecto importante del Lenguaje de Expresión de LangChain (LangChain Expression Language) es que los runnables pueden encadenarse en secuencias. La salida de la llamada .invoke() de un runnable anterior se pasa como entrada al siguiente runnable.\n",
        "\n",
        "Esto se puede hacer utilizando el operador pipe (|) o el método más explícito .pipe(), que funciona de la misma manera.\n",
        "\n",
        "El RunnableSequence resultante es en sí mismo un runnable, lo que significa que puede invocarse, transmitirse en streaming o seguir encadenándose como cualquier otro runnable."
      ],
      "metadata": {
        "id": "JsbjodIxTHof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una cadena prompt - modelo.\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un asistente experto en matemáticas, responde de manera breve y directa\"),\n",
        "    (\"user\", \"{question}\")\n",
        "])\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "chain"
      ],
      "metadata": {
        "id": "-oLYLJL7HiYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se utiliza la cadena para generar una respuesta.\n",
        "\n",
        "question = '¿Cuáles son los primeros 10 dígitos del número Pi?'\n",
        "response = chain.invoke(question)\n",
        "response.content"
      ],
      "metadata": {
        "id": "WaUZjOzvJB4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se intenta obtener una respuesta basada en memoria.\n",
        "\n",
        "question = '¿Cuáles son los siguientes 10?'\n",
        "response = chain.invoke(question)\n",
        "response.content"
      ],
      "metadata": {
        "id": "McnxbjiWZI00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "eU4z9GMIT3L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilizando cadenas con memoria"
      ],
      "metadata": {
        "id": "psGKEjUdYEjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea una cadena con una variable para el historial.\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"Eres un asistente experto en matemáticas, responde de manera breve y directa\"),\n",
        "    MessagesPlaceholder(variable_name=\"history\"),\n",
        "    (\"user\", \"{question}\"),\n",
        "])\n",
        "\n",
        "chain = prompt | model\n",
        "\n",
        "chain"
      ],
      "metadata": {
        "id": "uA7uCIK1Ik2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se crea un runable que considere los mensajes pasados como contexto.\n",
        "\n",
        "chain_with_history = RunnableWithMessageHistory(\n",
        "    chain, # El runnable base (puede ser un modelo de lenguaje)\n",
        "    get_by_session_id, # Función que recupera el historial de mensajes\n",
        "    input_messages_key=\"question\", # Clave en la entrada donde está la pregunta del usuario\n",
        "    history_messages_key=\"history\", # Clave en la entrada donde se almacenan los mensajes previos\n",
        ")"
      ],
      "metadata": {
        "id": "yqMd3xEqKhlS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se añaden mensajes al historial, ahora con un nuevo ID.\n",
        "response = chain_with_history.invoke({\"question\": \"¿Cuáles son los primeros 10 dígitos del número Pi?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"2\"}}\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "id": "P_cLGPyqKl9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se revisa el estado actual del almacenamiento.\n",
        "store"
      ],
      "metadata": {
        "id": "i4qWmGa4LIJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain_with_history.invoke({\"question\": \"¿Cuáles son los siguientes 10?\"},\n",
        "    config={\"configurable\": {\"session_id\": \"2\"}}\n",
        ")\n",
        "\n",
        "response.content"
      ],
      "metadata": {
        "id": "_GqtlXlYMHyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en: https://python.langchain.com/api_reference/core/runnables/langchain_core.runnables.history.RunnableWithMessageHistory.html"
      ],
      "metadata": {
        "id": "nJaVkNUfM4hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "097v10PjAa5G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Herramientas disponibles por LangChain: https://python.langchain.com/docs/integrations/tools/\n",
        "\n",
        "Más información en: https://python.langchain.com/docs/concepts/tools/"
      ],
      "metadata": {
        "id": "81-9Vq9-AeBO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "IxeT_AvA3ERH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}