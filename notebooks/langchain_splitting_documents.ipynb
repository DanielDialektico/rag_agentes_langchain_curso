{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvEH1+K4Bd0XyOiYnSH1OZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DanielDialektico/rag_agentes_langchain_curso/blob/main/notebooks/langchain_splitting_documents.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://dialektico.com/wp-content/uploads/2023/03/MiniLogoW4.png\" alt=\"Dialéktico Logo\" />"
      ],
      "metadata": {
        "id": "Vc-8Grt7ORmW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este pequeño tutorial pertenece al curso de RAG y agentes con LangChain al que puedes acceder mediante la siguiente URL: https://www.youtube.com/playlist?list=PLlWTv9_GeWd32stuEMWpYOnxiVxnXaU6q\n",
        "\n",
        "Sigue los videos del curso para recibir instrucciones y contexto sobre la ejecución de este Notebook."
      ],
      "metadata": {
        "id": "FdVKmZZtOT3l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "ad-poWzqOWWd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Se instalan e importan las librerías"
      ],
      "metadata": {
        "id": "qFIVZvp0OZ2-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.20\n",
        "!pip install langchain-community==0.3.20\n",
        "!pip install pypdf==5.4.0\n",
        "!pip install beautifulsoup4==4.13.3\n",
        "!pip install tiktoken==0.9.0"
      ],
      "metadata": {
        "id": "8U_GtE_0tuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dTpru6JOFTj"
      },
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader, WebBaseLoader\n",
        "from langchain_text_splitters import CharacterTextSplitter, RecursiveCharacterTextSplitter\n",
        "import bs4\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "-FoCFQISWQSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cargar y dividir documentos con LangChain"
      ],
      "metadata": {
        "id": "7HnRYF3bHbYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un paso fundamental en un sistema RAG es la carga y división de documentos en fragmentos informativos, los cuales serán posteriormente vectorizados y almacenados en una base de datos.\n",
        "\n",
        "Seguiremos los siguientes pasos:\n",
        "\n",
        "**Cargar**: Cargar documentos para su división. Esto se hace con Document Loaders (cargadores de documentos).\n",
        "\n",
        "**Dividir**: Utizaremos Text Splitters (divisores de texto), los cuales dividen documentos grandes en fragmentos más pequeños. Esto es útil tanto para indexar los datos como para pasarlos a un modelo, ya que los fragmentos grandes son más difíciles de buscar y no caben en la ventana de contexto limitada de un modelo."
      ],
      "metadata": {
        "id": "PIbYz1WkP3Q9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de información de PDF"
      ],
      "metadata": {
        "id": "TcvsoVYZCPCv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga el documento PDF.\n",
        "loader = PyPDFLoader('/content/Aviso_de_privacidad.pdf')\n",
        "pdf_pages = []\n",
        "async for page in loader.alazy_load():\n",
        "    pdf_pages.append(page)"
      ],
      "metadata": {
        "id": "XHHwywzLv15h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprime la lista.\n",
        "pdf_pages"
      ],
      "metadata": {
        "id": "Th-pk2vyv7rR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprimen los metadatos de una página.\n",
        "print(f\"{pdf_pages[0].metadata}\\n\")"
      ],
      "metadata": {
        "id": "IPUFDwhCwV2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprime el contenido de una página.\n",
        "print(pdf_pages[0].page_content)"
      ],
      "metadata": {
        "id": "MSEhtS_VwudJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "6pYdyGPWxh2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carga de información de página web"
      ],
      "metadata": {
        "id": "iVJ1zw6bzQiR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se carga la información de una página web.\n",
        "\n",
        "page_url = \"https://dialektico.com/cama-ultra-lujosa-para-gatos-dialektiroyal-comfort/\"\n",
        "\n",
        "loader = WebBaseLoader(web_paths=[page_url])\n",
        "docs = []\n",
        "async for doc in loader.alazy_load():\n",
        "    docs.append(doc)"
      ],
      "metadata": {
        "id": "KeMaLYkxzngJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Se imprime la información recabada.\n",
        "docs"
      ],
      "metadata": {
        "id": "xdVA4-Xt0K_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para conocer más opciones de carga de información, puede consultarse:\n",
        "https://python.langchain.com/docs/concepts/text_splitters/\n",
        "\n"
      ],
      "metadata": {
        "id": "JLMI63490lNa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "uf8qL1N51YN6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dividir documentos\n",
        "\n",
        "Después de haber cargado la información se debe realizar una división de estos en fragmentos informativos más pequeños.\n",
        "\n",
        "**¿Por qué dividir documentos?**\n",
        "Existen varias razones para dividir documentos:\n",
        "\n",
        "* **Manejo de longitudes no uniformes**: Las colecciones de documentos del mundo real suelen contener textos de diferentes tamaños. Dividirlos garantiza un procesamiento consistente entre todos los documentos.\n",
        "\n",
        "* **Superar las limitaciones del modelo**: Muchos modelos de embeddings y modelos de lenguaje tienen restricciones en el tamaño máximo de entrada. Dividir permite procesar documentos que, de otro modo, excederían esos límites.\n",
        "\n",
        "* **Mejorar la calidad de la representación**: En documentos largos, la calidad de los embeddings u otras representaciones puede degradarse al intentar capturar demasiada información. Dividirlos puede generar representaciones más precisas y enfocadas de cada sección.\n",
        "\n",
        "* **Aumentar la precisión en la recuperación de información**: En sistemas de recuperación de información, dividir documentos puede mejorar la granularidad de los resultados, permitiendo una correspondencia más precisa entre consultas y secciones relevantes del documento.\n",
        "\n",
        "* **Optimizar los recursos computacionales**: Trabajar con fragmentos más pequeños de texto puede ser más eficiente en memoria y permite una mejor paralelización de las tareas de procesamiento."
      ],
      "metadata": {
        "id": "jSEt65PR1_Qx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracción basada en longitud"
      ],
      "metadata": {
        "id": "6Ax9BGYQ2U4K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La estrategia más intuitiva es dividir los documentos en función de su longitud. Este enfoque, simple pero eficaz, garantiza que cada fragmento no supere un límite de tamaño especificado. Los principales beneficios de la división basada en longitud son:\n",
        "\n",
        "* Implementación sencilla\n",
        "\n",
        "* Tamaños de fragmento consistentes\n",
        "\n",
        "* Fácil adaptación a los requisitos de diferentes modelos\n",
        "\n",
        "Tipos de división basada en longitud:\n",
        "* Basada en tokens: Divide el texto según el número de tokens, lo cual es útil al trabajar con modelos de lenguaje.\n",
        "\n",
        "* Basada en caracteres: Divide el texto según el número de caracteres, lo cual puede ser más consistente entre distintos tipos de texto."
      ],
      "metadata": {
        "id": "VC7gbXR-2rTJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## División basada en tokens"
      ],
      "metadata": {
        "id": "aG3XlB5F21bZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se divide el texto utilizando el tokenizador tiktoken.\n",
        "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
        "    encoding_name=\"cl100k_base\", chunk_size=1000, chunk_overlap=200\n",
        ")\n",
        "texts = text_splitter.split_documents(pdf_pages)"
      ],
      "metadata": {
        "id": "NzKmMvvd206C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0].page_content"
      ],
      "metadata": {
        "id": "u4E1e_lD3YQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Se ha dividido la información en {len(texts)} documentos (chunks).\")"
      ],
      "metadata": {
        "id": "a2jfumxA34ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# División basada en caracteres y estructura del texto"
      ],
      "metadata": {
        "id": "akAi89rQ48uq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El texto está naturalmente organizado en unidades jerárquicas como párrafos, oraciones y palabras. Podemos aprovechar esta estructura inherente para definir una estrategia de división que mantenga el flujo natural del lenguaje, preserve la coherencia semántica dentro de cada fragmento y se adapte a distintos niveles de granularidad del texto. El RecursiveCharacterTextSplitter de LangChain implementa este concepto:\n",
        "\n",
        "* RecursiveCharacterTextSplitter intenta mantener intactas las unidades más grandes (por ejemplo, los párrafos).\n",
        "\n",
        "* Si una unidad supera el tamaño máximo del fragmento, pasa al siguiente nivel (por ejemplo, las oraciones).\n",
        "\n",
        "* Este proceso continúa hasta el nivel de las palabras, si es necesario.\n"
      ],
      "metadata": {
        "id": "6KCuQwCm5XNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200\n",
        ")\n",
        "texts = text_splitter.split_documents(pdf_pages)"
      ],
      "metadata": {
        "id": "mVHEsUaj5OqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts[0].page_content"
      ],
      "metadata": {
        "id": "iBjgbQLu6bYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Se ha dividido la información en {len(texts)} sub-documentos.\")"
      ],
      "metadata": {
        "id": "LRNUWnCLyJ1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Diferencia entre dividir por tokens y caracteres\n",
        "\n",
        "🔤 División por caracteres:\n",
        "* Se basa en la cantidad de letras, espacios y símbolos que contiene el texto.\n",
        "* Es una forma muy directa y uniforme de dividir.\n",
        "* No considera palabras completas, estructuras lingüísticas ni unidades semánticas.\n",
        "\n",
        "Ejemplo: \"Hola, ¿cómo estás?\" tiene 18 caracteres (incluyendo signos y espacios).\n",
        "\n",
        "🧱 División por tokens:\n",
        "* Se basa en el número de tokens generados por un tokenizador (como el de OpenAI o HuggingFace).\n",
        "* Un token no siempre es igual a una palabra: A veces una sola palabra genera 2 o más tokens. Palabras muy comunes generan menos tokens.\n",
        "* Es útil cuando trabajas con modelos LLM porque ellos procesan tokens, no caracteres."
      ],
      "metadata": {
        "id": "Eb4kbvTU85xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Cuál elegir?\n",
        "\n",
        "<br>\n",
        "<center><img src=\"https://dialektico.com/wp-content/uploads/2025/03/tabla_cursoRAG_2.png\" width=\"800\" /></center>"
      ],
      "metadata": {
        "id": "cpMWSYiX7Tl6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Más información en:\n",
        "- https://python.langchain.com/api_reference/text_splitters/index.html\n",
        "- https://python.langchain.com/docs/concepts/text_splitters/"
      ],
      "metadata": {
        "id": "nJaVkNUfM4hz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br>"
      ],
      "metadata": {
        "id": "IxeT_AvA3ERH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dialektico Machine learning practices © 2025 by Daniel Antonio García Escobar\n",
        "# is licensed under CC BY-NC 4.0. To view a copy of this license,\n",
        "# visit https://creativecommons.org/licenses/by-nc/4.0/\n",
        "\n",
        "# Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International\n",
        "# Public License"
      ],
      "metadata": {
        "id": "7ly3JFP2WEOd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}